{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial import polynomial as P\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # TOPVIEW_PERSPECTIVE_TRANSFORM -- Those points are actualy x,y of the left and right lanes from straigh_lines1.jpg\n",
    "        # Need to work this out to automate it\n",
    "        self.HYPERPARAMETERS = {    \"MAIN\" : {\"RUN\" : \"TESTRUN\"},\n",
    "                                    \"PATH\" : {\"CALIB\":\"../camera_cal/\",\n",
    "                                              \"TEST\" :\"../test_images/\",\n",
    "                                              \"PICKLE\":\"../pickle_output/\"\n",
    "                                                  },\n",
    "                                    \"PICKLE_FILES\" : {\"CALIB\" : \"calibration_data.pickle\",\n",
    "                                                       \"PARAMETERS\" : \"hyperparameters.pickle\"\n",
    "                                                     },\n",
    "                                    \"CAMERA_CALIBRATION\" : {\"CAMERAMATRIX\" : np.zeros((3,3)),\n",
    "                                                            \"DISTORTIONCOEFF\" : ()\n",
    "                                                           },\n",
    "                                    \"CANNY\" : {\"LOW_THRESHOLD\" : 80,\n",
    "                                              \"HIGH_THRESHOLD)\": 240\n",
    "                                              },\n",
    "                                    \"GAUSSIAN_BLUR\" : {\"KERNEL_SIZE\" : 17\n",
    "                                                      },\n",
    "                                 \n",
    "                                    \"DETECT_AND_DRAW_CORNERS\" : {\"NX_CORNERS_PER_ROW\": 9,\n",
    "                                                             \"NY_CORNERS_PER_COLUMN\": 6,\n",
    "                                                             \"WINSIZE\" : (10, 10),\n",
    "                                                             \"ZEROZONE\" :( -1, -1 ),\n",
    "                                                             \"CRITERIA\" : (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 40, 0.001)\n",
    "                                                            },\n",
    "                                     \"TRANFORMATION_MATRICES\" : {\"LEFT_BOTTOM_CORNER\" : [209, 719],\n",
    "                                                                 \"RIGHT__BOTTOM_CORNER\" : [1114, 719],\n",
    "                                                                 \"LEFT_TOP_CORNER\" : [601,445],\n",
    "                                                                 \"RIGHT_TOP_CORNER\" :[682,445] \n",
    "                                                                 },\n",
    "                                    \"GRADIENT_THRESHOLD\": {\"GRAY_THRESH_MIN\": 20,\n",
    "                                                   \"GRAY_THRESH_MAX\": 100,\n",
    "                                                   \"HLS_S_THRESH_MIN\": 120,\n",
    "                                                   \"HLS_S_THRESH_MAX\": 255\n",
    "                                                          },\n",
    "                                    \"GRADIENT_BY_COLOR_AND_FILTER\" : {\"SOBEL_KERNEL\" : 3,\n",
    "                                                                      \"SOBEL_ABSX_MIN_THRESHOLD\": 20,\n",
    "                                                                      \"SOBEL_ABSX_MAX_THRESHOLD\": 100,\n",
    "                                                                      \"SOBEL_MAG_MIN_THRESHOLD\": 30,\n",
    "                                                                      \"SOBEL_MAG_MAX_THRESHOLD\": 100,\n",
    "                                                                      \"SOBEL_DIR_MIN_THRESHOLD\": 0,\n",
    "                                                                      \"SOBEL_DIR_MAX_THRESHOLD\": 1,\n",
    "                                                                      \"HLS_S_MIN_THRESHOLD\" : 120,\n",
    "                                                                      \"HLS_S_MAX_THRESHOLD\" : 255, \n",
    "                                                                      \"RGB_R_MIN_THRESHOLD\" : 220,\n",
    "                                                                      \"RGB_R_MAX_THRESHOLD\" : 255,\n",
    "                                                                      \"RGB_G_MIN_THRESHOLD\" : 200,\n",
    "                                                                      \"RGB_G_MAX_THRESHOLD\" : 255\n",
    "                                                                           },\n",
    "                                    \"INITIAL_FIT_POLYNOMIAL\": {\"NWINDOWS\" : 9,\n",
    "                                                               \"MARGIN\" : 100,\n",
    "                                                               \"MINPIX\" : 50\n",
    "                                                        },\n",
    "                                    \"FITPOLY_USING_PRIORFIT\" : {\"MARGIN\" : 200},\n",
    "\n",
    "                                    \"MEASURE_CURVATURE_REAL\" : {\"Y_METERS_PER_PIXEL\" : 30/720,\n",
    "                                                                \"X_METERS_PER_PIXEL\" : 3.7/700\n",
    "                                                               },\n",
    "                                    \"DRAW_FINAL_LANES\" : {\"ORGIMG_WEIGHT\" : 1,\n",
    "                                                          \"WARPIMG_WEIGHT\" : 0.3\n",
    "                                                         },\n",
    "\n",
    "                                    \"HOUGH_TRANSFORM\" : { \"RHO\" : 1,\n",
    "                                                          \"THETA\" : np.pi/180,\n",
    "                                                          \"THRESHOLD\" : 50,\n",
    "                                                          \"MIN_LINE_LENGTH\" : 30,\n",
    "                                                          \"MAX_LINE_GAP\" : 25\n",
    "                                                        },\n",
    "                                    }\n",
    "    def get_paramDict(self,key):\n",
    "        return self.HYPERPARAMETERS[key]\n",
    "    \n",
    "    def get_fullDict(self):\n",
    "        return self.HYPERPARAMETERS\n",
    "\n",
    "    def set_paramDict(self, updateDict):\n",
    "        for key, value in updateDict.items():\n",
    "            for k, v in value.items():\n",
    "                if v is not None:\n",
    "                    self.HYPERPARAMETERS[key][k] = v\n",
    "                        \n",
    "#. Define a class to receive the characteristics of each line detection                     \n",
    "class Line():\n",
    "    def __init__(self):  \n",
    "        self.detected   = []                                # was the line detected in the last iteration?\n",
    "        self.sanityCheckDict = []               # List of Dict - Left/Right TOP, BOTTOM, MID, and distances\n",
    "        self.polyFitDataCurrent = []                        # current (left_fit, right_fit, left_fitx, right_fitx)\n",
    "        self.ROCData   = []                                 # ROC and Car Center data\n",
    "        self.polyFitDataQueue = collections.deque([])       # last n (left_fit, right_fit, left_fitx, right_fitx)\n",
    "        self.pixelPositionsQueue = collections.deque([])    # leftx and rightx (pixels around polynomial)\n",
    "        self.polyfitDataSum = None                          # For quick calculation of n data avg\n",
    "        self.polyfitDataAvg  = None                         # Avg of left_fit, right_fit, left_fitx, right_fitx\n",
    "        self.polyFitDiff = np.array([0,0,0], dtype='float') # difference in fit coefficients between last and new fits\n",
    "        self.curvatureData = []\n",
    "        self.frameCount = 0\n",
    "        self.badFrames = 0\n",
    "        \n",
    "class Save_Images():\n",
    "    def __init__(self):\n",
    "        self.SAVED_IMAGES_DICT = {  \"PATH\"  :        {\"CALIB\":\"../pickle_output/\",\n",
    "                                                      \"TEST\" :\"../pickle_output/\" },\n",
    "                                    \"PICKLE_FILES\" : { \"CALIB\": \"calibimages.pickle\",\n",
    "                                                       \"TEST\": \"testimages.pickle\"\n",
    "                                                     },\n",
    "                                     \"CALIB_IMAGES\": {\"ORIGINAL\":[],\n",
    "                                                      \"WITHCORNERS\" :[]  \n",
    "                                                     },\n",
    "                                      \"TEST_IMAGES\"  : {}\n",
    "                                }\n",
    "        self.singleFileDict = {  \n",
    "                              }\n",
    "        \n",
    "    def save_images_dict(self, key1, key2, value):\n",
    "        self.SAVED_IMAGES_DICT[key1][key2].append(value)\n",
    "\n",
    "    def get_imageDict(self, key):\n",
    "        return self.SAVED_IMAGES_DICT[key]\n",
    "    \n",
    "\n",
    "\n",
    "def tune_hyper_paramters(func_name,paramInstance, **kwargs):\n",
    "    \"\"\"\n",
    "    sets the parameters values of functions in the class Parameters\n",
    "    \"\"\"\n",
    "    updateDict = {func_name : {**kwargs}}\n",
    "    paramInstance.set_paramDict(updateDict)\n",
    "        \n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "        This will return an image with only one color channel\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, paramInstance, key):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    kernel_size = paramDict[\"KERNEL_SIZE\"]\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def detect_and_draw_corners(path, paramInstance, key,  calibImagesInstance):\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    nx = paramDict[\"NX_CORNERS_PER_ROW\"]\n",
    "    ny = paramDict[\"NY_CORNERS_PER_COLUMN\"]\n",
    "    \n",
    "    objp = np.zeros((nx * ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    imgPoints = []\n",
    "    objPoints = []\n",
    "    \n",
    "    for filename in glob.glob(path + \"*.jpg\"):\n",
    "        originalImage = mpimg.imread(filename)\n",
    "        calibImagesInstance.save_images_dict(\"CALIB_IMAGES\", \"ORIGINAL\", [filename,originalImage])\n",
    "        distortedImage = np.copy(originalImage)\n",
    "        grayImage = cv2.cvtColor(originalImage, cv2.COLOR_RGB2GRAY)\n",
    "        imgSize = grayImage.shape[::-1]\n",
    "        ret, corners = cv2.findChessboardCorners(grayImage, (nx, ny), None)\n",
    "        if ret:\n",
    "            winSize  = paramDict[\"WINSIZE\"]\n",
    "            zeroZone = paramDict[\"ZEROZONE\"]\n",
    "            criteria = paramDict[\"CRITERIA\"]\n",
    "            corners  = cv2.cornerSubPix( grayImage, corners, winSize, zeroZone, criteria );\n",
    "            cv2.drawChessboardCorners(distortedImage, (nx, ny), corners, ret)\n",
    "            imgPoints.append(corners)\n",
    "            objPoints.append(objp)\n",
    "            calibImagesInstance.save_images_dict(\"CALIB_IMAGES\", \"WITHCORNERS\",[filename,distortedImage])\n",
    "           \n",
    "    return imgSize, imgPoints, objPoints\n",
    "            \n",
    "               \n",
    "def camera_calibration(path, paramInstance, key, calibImagesInstance):\n",
    "    \"\"\"\n",
    "    returnedTuple = (success, cameraMatrix, distortionCoeff, rvecs, tvecs)\n",
    "    \"\"\"\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    imgSize, imgPoints, objPoints = detect_and_draw_corners(path, paramInstance, \"DETECT_AND_DRAW_CORNERS\", calibImagesInstance)\n",
    "    returnedTuple =  cv2.calibrateCamera(objPoints, imgPoints, imgSize, None, None)\n",
    "    \n",
    "    success = returnedTuple[0]\n",
    "    cameraMatrix = returnedTuple[1]\n",
    "    distortionCoeff = returnedTuple[2]\n",
    " \n",
    "    if success:\n",
    "        updateDict = {\"CAMERA_CALIBRATION\" : {\"CAMERAMATRIX\" : cameraMatrix,\n",
    "                                              \"DISTORTIONCOEFF\" : distortionCoeff\n",
    "                                            }\n",
    "                     }\n",
    "        paramInstance.set_paramDict(updateDict)\n",
    "    else:\n",
    "        print(\"Something wrong with Calibration!!\")\n",
    "        raise\n",
    "    \n",
    "def draw_region_of_interest(originalImage):\n",
    "    return cv2.polylines(originalImage,np.int32(np.array([[left,apex_left,apex_right,right]])),True,(0,0,255),10)\n",
    "\n",
    "\n",
    "def undistort_image(image, cameraMatrix, distortionCoeff):\n",
    "    return cv2.undistort(image, cameraMatrix, distortionCoeff, None, cameraMatrix)\n",
    "\n",
    "\n",
    "def get_channel_binary(channel_img, paramDict, imgType=\"RGB\", channel_color='R'):\n",
    "    prefix = imgType + \"_\" + channel_color\n",
    "    thresh = (paramDict[prefix + \"_MIN_THRESHOLD\"], paramDict[prefix + \"_MAX_THRESHOLD\"])\n",
    "    \n",
    "    channel_binary = np.zeros_like(channel_img)\n",
    "    channel_binary[(channel_img >= thresh[0]) & (channel_img <= thresh[1])] = 1\n",
    "    \n",
    "    return channel_binary\n",
    "\n",
    "def get_color_channel_binaries(img, paramDict):\n",
    "    \"\"\"\n",
    "    img is original Warped color image - \n",
    "    by default it is RGB since we used mpimg.imread to read the original image\n",
    "    For project, will be using only R, G and S channels for detection of lane lines\n",
    "    As they give better results for White and Yellow lanes\n",
    "    \"\"\"\n",
    "    HLS = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    R, G, B  = (img[:,:,0], img[:,:,1], img[:,:,2])  # using B only for Analysis\n",
    "    H, L, S  = (HLS[:,:,0], HLS[:,:,1], HLS[:,:,2])\n",
    "    R_binary = get_channel_binary(R, paramDict, imgType=\"RGB\",channel_color='R')\n",
    "    G_binary = get_channel_binary(G, paramDict, imgType=\"RGB\",channel_color='G')\n",
    "    S_binary = get_channel_binary(S, paramDict, imgType=\"HLS\",channel_color='S')\n",
    "    \n",
    "    return R, G, B, H, L, S, R_binary, G_binary, S_binary\n",
    "\n",
    "def get_sobel_binary(gray, paramDict, orient='X', flag='ABS'):\n",
    "    if flag == \"ABS\":\n",
    "        flag += orient\n",
    "    \n",
    "    sobel_kernel = paramDict[\"SOBEL_KERNEL\"]\n",
    "    \n",
    "    thresh = (paramDict[\"SOBEL_\"+flag+\"_MIN_THRESHOLD\"], paramDict[\"SOBEL_\"+flag+\"_MAX_THRESHOLD\"])\n",
    "    \n",
    "    gradientx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    gradienty = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    \n",
    "    if (flag == \"ABSX\"):\n",
    "        value = np.absolute(gradientx)\n",
    "    elif (flag == \"ABSY\"):\n",
    "        value = np.absolute(gradienty)\n",
    "    elif flag == \"MAG\":\n",
    "        value = np.sqrt((gradientx ** 2) + (gradienty ** 2))\n",
    "    elif flag == \"DIR\":\n",
    "        value = np.arctan2(np.absolute(gradienty), np.absolute(gradientx))\n",
    "        \n",
    "    if flag == \"DIR\" :\n",
    "        scaled_sobel = value\n",
    "    else:\n",
    "        scaled_sobel = np.uint8(255*value / np.max(value))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(value >= thresh[0]) & (value <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def gradient_by_color_and_filter(fname, warpedImage, paramInstance, key, testImagesInstance, mode): \n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    gray = cv2.cvtColor(warpedImage, cv2.COLOR_RGB2GRAY)\n",
    "    grayBlur = gaussian_blur(gray, paramInstance, \"GAUSSIAN_BLUR\")\n",
    "    \n",
    "    RGSImages = get_color_channel_binaries(warpedImage, paramDict)\n",
    "    R, G, B, H, L, S, R_binary, G_binary, S_binary = RGSImages\n",
    "    sobelx_binary = get_sobel_binary(grayBlur,  paramDict, orient='X', flag = 'ABS')\n",
    "    mag_binary = get_sobel_binary(grayBlur, paramDict, orient='X', flag = 'MAG')\n",
    "    dir_binary = get_sobel_binary(grayBlur, paramDict, orient='X', flag = 'DIR')\n",
    "    \n",
    "    combined_binary = np.zeros_like(sobelx_binary)\n",
    "    combined_binary[(sobelx_binary == 1 ) | ((mag_binary == 1) & (dir_binary == 1)) |\n",
    "                    (R_binary == 1) | (G_binary == 1)  | (S_binary == 1)] = 1\n",
    "    \n",
    "    if mode == \"TESTRUN\":\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"GRAY\"] = gray\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"GRAY_BLUR\"] = grayBlur\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"R_CHANNEL\"] = R\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"G_CHANNEL\"] = G\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"B_CHANNEL\"] = B\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"H_CHANNEL\"] = H\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"L_CHANNEL\"] = L\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"S_CHANNEL\"] = S  \n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"R_BINARY\"] = R_binary\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"G_BINARY\"] = G_binary\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"S_BINARY\"] = S_binary\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"SOBEL_ABSX\"] = sobelx_binary\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"SOBEL_MAG\"] = mag_binary\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"SOBEL_DIR\"] = dir_binary\n",
    "       \n",
    "    return (combined_binary)\n",
    "\n",
    "def tranformation_matrices(imgSize, paramInstance, key):\n",
    "    \"\"\"\n",
    "    This function needs to be evaluated once\n",
    "    It is assumed that the imgSize will remain constant for all Test Images and VideoFrames\n",
    "    \"\"\"\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    left= paramDict[\"LEFT_BOTTOM_CORNER\"]\n",
    "    right=paramDict[\"RIGHT__BOTTOM_CORNER\"] \n",
    "    apex_left=paramDict[\"LEFT_TOP_CORNER\"]\n",
    "    apex_right=paramDict[\"RIGHT_TOP_CORNER\"] \n",
    "\n",
    "    height, width = imgSize\n",
    "    X_offset = width//5\n",
    "    Y_offset = 0\n",
    "    \n",
    "    src=np.float32([left,apex_left,apex_right,right]) \n",
    "    dst = np.float32([[X_offset, height], [X_offset, Y_offset], [width - X_offset, Y_offset],[width - X_offset, height]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    MInv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return M, MInv\n",
    "\n",
    "\n",
    "def topview_perspective_transform(image, M, warpImgSize, paramInstance, key): \n",
    "    \"\"\"\n",
    "    Create top view of the lanes\n",
    "    \"\"\"\n",
    "    warpedImage = cv2.warpPerspective(image, M, warpImgSize, flags=cv2.INTER_LINEAR)\n",
    "    return warpedImage\n",
    "\n",
    "def rectangle_diagonal_points(n, staticData, leftCenter, rightCenter):\n",
    "    imageHeight, windowHeight, margin = staticData\n",
    "    \n",
    "    y_low  = imageHeight - ((n+1) * windowHeight)\n",
    "    y_high = imageHeight - (n * windowHeight)\n",
    "    xleft_low = leftCenter - margin\n",
    "    xleft_high = leftCenter + margin\n",
    "    xright_low = rightCenter - margin\n",
    "    xright_high = rightCenter + margin\n",
    "    \n",
    "    leftDiagonalPts  = [(xleft_low, y_low ), (xleft_high, y_high)]\n",
    "    rightDiagonalPts = [(xright_low, y_low ), (xright_high, y_high)]\n",
    "    \n",
    "    return leftDiagonalPts, rightDiagonalPts\n",
    "\n",
    "#def nonZeroPixelsInWindow(nonzero, nonzerox, nonzeroy, diagonalPoints):\n",
    "def nonZeroPixelsInWindow(nonzerox, nonzeroy, diagonalPoints):\n",
    "    \"\"\"\n",
    "    Identifies the nonzero pixels in x and y within the window \n",
    "    \"\"\"\n",
    "    x_low, y_low = diagonalPoints[0]\n",
    "    x_high, y_high = diagonalPoints[1]\n",
    "\n",
    "    indices = ((nonzeroy >= y_low) & \n",
    "                 (nonzeroy < y_high) & \n",
    "                 (nonzerox >= x_low) & \n",
    "                 (nonzerox < x_high)).nonzero()[0]  ## get all left indices\n",
    "    return indices\n",
    " \n",
    "def extract_pixel_positions(nonZeroX, nonZeroY ,left_lane_inds, right_lane_inds):\n",
    "    leftx = nonZeroX[left_lane_inds]\n",
    "    lefty = nonZeroY[left_lane_inds] \n",
    "    rightx = nonZeroX[right_lane_inds]\n",
    "    righty = nonZeroY[right_lane_inds]\n",
    "    \n",
    "    return (leftx, lefty, rightx, righty)\n",
    "\n",
    "def recenter_window(currentCenter, nonZeroX, good_indices, minpix):\n",
    "    if len(good_indices) > minpix:\n",
    "        return np.int(np.mean(nonZeroX[good_indices]))\n",
    "    return currentCenter\n",
    " \n",
    "def evaluate_polynomial_func(fitData, Y, degree):\n",
    "    \"\"\"\n",
    "    y-axis points => ploty\n",
    "    x-axis points => f(y) => A*Y**2 + B*Y + C\n",
    "    \"\"\"\n",
    "    A = fitData[2]\n",
    "    B = fitData[1]\n",
    "    C = fitData[0]\n",
    "    \n",
    "    if degree == 2:\n",
    "        try:\n",
    "            fitx =  (A * Y**2) + (B * Y) + C                # X = f(Y) = AY^2 + BY + C\n",
    "\n",
    "        except TypeError:\n",
    "            print('The function failed to fit a line! Applied work-around')\n",
    "            fitx = (1 * Y**2) + (1 * Y)                     # X = f(Y) = Y^2 + Y\n",
    "    \n",
    "    elif degree == 1:\n",
    "        numerator = (1 + (((2 * A * Y) + B) ** 2)) ** (3/2)  # X = f(Y) = { [(1 + (2AY + B)^2]^3/2 } / (|2A|)\n",
    "        denominator = np.absolute(2 * A)\n",
    "        fitx = numerator/denominator\n",
    "    \n",
    "    return fitx\n",
    "    \n",
    "\n",
    "def find_lane_pixels(fname, binary_warped, paramDict,ploty, mode, testImageInstance ):\n",
    "    \"\"\"\n",
    "    pixelPositions: leftx  : X-Coordinates of LeftLane,  along high histogram peak, of All defined Sliding Windows\n",
    "                    lefty  : Y-Coordinates of LeftLane,  along high histogram peak, of All defined Sliding Windows\n",
    "                    rightx : X-Coordinates of RightLane, along high histogram peak, of All defined Sliding Windows\n",
    "                    righty : Y-Coordinates of RightLane, along high histogram peak, of All defined Sliding Windows\n",
    "    \"\"\"\n",
    "    nwindows = paramDict[\"NWINDOWS\"]\n",
    "    margin   = paramDict[\"MARGIN\"]\n",
    "    minpix   = paramDict[\"MINPIX\"]\n",
    "    \n",
    "    histogram      = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    out_img        = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    midpoint       = np.int(histogram.shape[0]//2)\n",
    "    leftx_base     = np.argmax(histogram[:midpoint])\n",
    "    rightx_base    = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    leftx_current  = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    imageHeight    = binary_warped.shape[0]\n",
    "    windowHeight   = np.int(binary_warped.shape[0]//nwindows)\n",
    "    nonZero        = binary_warped.nonzero()     # [(y1, y2,...)(x1, x2, ...)]. All Indices where values are 1\n",
    "    nonZeroY       = np.array(nonZero[0])       # Just Y indices (y1, y2, y3...)  ..values range from 0..720\n",
    "    nonZeroX       = np.array(nonZero[1])       # Just X indices (x1, x2, x3...)  ..values range from 0..1280\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    staticData = (imageHeight, windowHeight, margin )\n",
    "    for n in range(nwindows):\n",
    "        leftDiagonalPts, rightDiagonalPoints = rectangle_diagonal_points(n, staticData, leftx_current, rightx_current ) \n",
    "        if mode == \"TESTRUN\":\n",
    "            cv2.rectangle(out_img,leftDiagonalPts[0],leftDiagonalPts[1],(0,255,0), 4) \n",
    "            cv2.rectangle(out_img,rightDiagonalPoints[0],rightDiagonalPoints[1],(0,255,0), 4)\n",
    "           \n",
    "        good_left_inds = nonZeroPixelsInWindow(nonZeroX, nonZeroY, leftDiagonalPts)\n",
    "        good_right_inds = nonZeroPixelsInWindow(nonZeroX, nonZeroY, rightDiagonalPoints)\n",
    " \n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # recenter next window on their mean position\n",
    "        leftx_current = recenter_window(leftx_current, nonZeroX, good_left_inds, minpix)\n",
    "        rightx_current = recenter_window(rightx_current, nonZeroX, good_right_inds, minpix)\n",
    "        \n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)   #Flatten -- [[1,2,3, [4,5,6]]] => [1,2,3,4,5,6]\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        print(\"value error in find_lane_pixes module!!!!\")\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    pixelPositions = extract_pixel_positions(nonZeroX, nonZeroY ,left_lane_inds, right_lane_inds )\n",
    "    visual_data = [nonZeroY, nonZeroX,  left_lane_inds, right_lane_inds, margin]\n",
    "    \n",
    "    polyfitData = get_polyfit_data(pixelPositions, ploty)\n",
    "    left_fitx, right_fitx = (polyfitData[2], polyfitData[3])\n",
    "    \n",
    "    out_img[nonZeroY[left_lane_inds], nonZeroX[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonZeroY[right_lane_inds], nonZeroX[right_lane_inds]] = [0, 0, 255]\n",
    "    polyWinData = [out_img, left_fitx, right_fitx, ploty]\n",
    "    if mode == \"TESTRUN\":\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"POLYWIN_IMGS\"] = polyWinData\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"HISTOGRAM\"] = histogram\n",
    "    \n",
    "    return pixelPositions, out_img, histogram, visual_data\n",
    "\n",
    "def get_polyfit_data(pixelPositions, ploty):\n",
    "    leftx, lefty, rightx, righty = pixelPositions\n",
    "    left_fit  = P.polyfit(lefty, leftx, 2)\n",
    "    right_fit = P.polyfit(righty, rightx, 2)\n",
    "    left_fitx  = evaluate_polynomial_func(left_fit, ploty, 2)\n",
    "    right_fitx = evaluate_polynomial_func(right_fit, ploty, 2)\n",
    "    \n",
    "    return (left_fit, right_fit, left_fitx, right_fitx) \n",
    "    \n",
    "def initial_fit_polynomial(fname, binary_warped, ploty, paramInstance, key, testImagesInstance, mode):\n",
    "    \"\"\"\n",
    "    polyfitData: Derived using pixelPositions data and polyfit function\n",
    "               : left_fit   : Coeffs (A,B,C) of the Left-Fit Polynomial (AY^2 + BY + C)\n",
    "               : right_fit  : Coeffs (A,B,C) of the Right-Fit Polynomial (AY^2 + BY + C)\n",
    "               : left_fitx  : LeftLane X-values derived using polyFunc (AY^2 + BY + C) for each Y in 0-710(imgHeight)\n",
    "               : right_fitx : RightLane X-values derived using polyFunc (AY^2 + BY + C) for each Y in 0-710(imgHeight)\n",
    "    \"\"\"\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    pixelPositions, out_img, histogram, visual_data = find_lane_pixels(fname, binary_warped, paramDict,ploty, mode, testImagesInstance)\n",
    "    polyfitData = get_polyfit_data(pixelPositions, ploty)\n",
    "    \n",
    "    if mode == \"TESTRUN\":\n",
    "        visual_data.append(polyfitData)\n",
    "        visual_data.append(ploty)\n",
    "        nonZeroY, nonZeroX, left_lane_inds, right_lane_inds, margin, polyfitData, ploty = visual_data\n",
    "        left_fitx, right_fitx = (polyfitData[2], polyfitData[3])\n",
    "        create_polyfill_outimg_for_visual(fname, binary_warped, visual_data, testImagesInstance)\n",
    "        leftx, lefty, rightx, righty = pixelPositions\n",
    " \n",
    "    return polyfitData, pixelPositions   #(left_fit, right_fit, left_fitx, right_fitx) \n",
    "\n",
    "def draw_final_lanes(undistortedImage, warpedImage, imgSize, Minv, ploty, fitXData, curvatureData, paramInstance, key):\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    orgImgWeight  = paramDict[\"ORGIMG_WEIGHT\"]\n",
    "    warpImgWeight = paramDict[\"WARPIMG_WEIGHT\"]\n",
    "    left_fitx , right_fitx = fitXData\n",
    "    avgRoc, distanceFromLaneCenter = (curvatureData[2],curvatureData[3])\n",
    "    ROCText = \"Radius of curvature is: {:.2f}\".format(avgRoc) + \" m\"\n",
    "    distanceText = \"Car is: {:.2f}\".format(np.abs(distanceFromLaneCenter)) \n",
    "    \n",
    "    if distanceFromLaneCenter < 0:\n",
    "        distanceText += \" m Left from Lane Center \"\n",
    "    else:\n",
    "        distanceText += \" m Right from Lane Center\"\n",
    "    \n",
    "    warp_zero = np.zeros_like(warpedImage).astype(np.uint8)     \n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])   \n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    imgsize = (undistortedImage.shape[1], undistortedImage.shape[0] )\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, imgsize)\n",
    "       \n",
    "    result = cv2.addWeighted(undistortedImage, orgImgWeight, newwarp, warpImgWeight, 0)\n",
    "    \n",
    "    cv2.putText(result,ROCText, (50,50), 2, 1, (255,255,255),2)\n",
    "    cv2.putText(result,distanceText, (50,100), 2, 1, (255,255,255),2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fitpoly_using_priorfit(binary_warped, ploty, fitData, paramInstance, key,testImageInstance, mode ):\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    margin = paramDict[\"MARGIN\"]\n",
    "    left_fit, right_fit = fitData\n",
    "    nonZero = binary_warped.nonzero()\n",
    "    nonZeroY = np.array(nonZero[0])  \n",
    "    nonZeroX = np.array(nonZero[1])  \n",
    "    polyLeft = evaluate_polynomial_func(left_fit, nonZeroY, 2) \n",
    "    left_lane_inds = ((nonZeroX > (polyLeft - margin)) & (nonZeroX < (polyLeft + margin)))\n",
    "    polyRight = evaluate_polynomial_func(right_fit, nonZeroY, 2) \n",
    "    right_lane_inds = ((nonZeroX > (polyRight - margin)) & (nonZeroX < (polyRight + margin)))\n",
    "    pixelPositions = extract_pixel_positions(nonZeroX, nonZeroY ,left_lane_inds, right_lane_inds )\n",
    "    polyfitData = get_polyfit_data(pixelPositions, ploty)\n",
    "    \n",
    "    if mode == \"TESTRUN\":\n",
    "        visual_data = (nonZeroY, nonZeroX,  left_lane_inds, right_lane_inds, polyfitData, ploty, margin)\n",
    "        create_polyfill_outimg_for_visual(binary_warped, visual_data, testImageInstance)\n",
    "    return polyfitData, pixelPositions\n",
    "\n",
    "def create_out_img_for_visual(binary_warped, visual_data, out_img):\n",
    "    nonZeroY, nonZeroX, left_lane_inds, right_lane_inds, margin, polyfitData, ploty = visual_data\n",
    "    left_fitx, right_fitx = (polyfitData[2], polyfitData[3])\n",
    "    if out_img is None:\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonZeroY[left_lane_inds], nonZeroX[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonZeroY[right_lane_inds], nonZeroX[right_lane_inds]] = [0, 0, 255]\n",
    "    return out_img\n",
    "    \n",
    "def create_polyfill_outimg_for_visual(fname, binary_warped, visual_data, testImagesInstance):\n",
    "    nonZeroY, nonZeroX, left_lane_inds, right_lane_inds, margin, polyfitData, ploty = visual_data\n",
    "    left_fitx, right_fitx = (polyfitData[2], polyfitData[3])\n",
    "    \n",
    "    out_img = create_out_img_for_visual(binary_warped, visual_data, None)\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    polyLineImg = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    polyLineData = [polyLineImg, left_fitx, right_fitx, ploty]\n",
    "    testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"POLYLINE_IMGS\"] = polyLineData\n",
    "\n",
    "\n",
    "def pickle_load(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        pickleDict = pickle.load(f)\n",
    "    \n",
    "    return pickleDict\n",
    "\n",
    "def pickle_dump(filename, inputDict):\n",
    "    \"\"\"\n",
    "    filename is fullpath : eg ../pickle_output/calibImages.pickle\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(inputDict, f)\n",
    "\n",
    "\n",
    "def pickledump_all_images(testImagesInstance):\n",
    "    \"\"\"\n",
    "    Pickle all generated images for anytime viewing\n",
    "    \"\"\"\n",
    "    calibDir = testImagesInstance.get_imageDict(\"PATH\")[\"CALIB\"]\n",
    "    calibFilename = testImagesInstance.get_imageDict(\"PICKLE_FILES\")[\"CALIB\"]\n",
    "    calibImagesDict = testImagesInstance.get_imageDict(\"CALIB_IMAGES\")\n",
    "    pickle_dump(calibDir + calibFilename, calibImagesDict)\n",
    "    \n",
    "    testDir = testImagesInstance.get_imageDict(\"PATH\")[\"TEST\"]\n",
    "    testFilename = testImagesInstance.get_imageDict(\"PICKLE_FILES\")[\"TEST\"]\n",
    "    testImagesDict = testImagesInstance.get_imageDict(\"TEST_IMAGES\")\n",
    "    pickle_dump(testDir + testFilename, testImagesDict)\n",
    "    \n",
    "def pickledump_all_Hyperparameters(paramInstance):\n",
    "    \"\"\"\n",
    "    Pickle all Hyperparameters - This is expected Tuned Parameters required for ProdRun\n",
    "    \"\"\"\n",
    "    allHyperparamDict = paramInstance.get_fullDict()\n",
    "    picklePath = allHyperparamDict[\"PATH\"][\"PICKLE\"]\n",
    "    pickleFile = allHyperparamDict[\"PICKLE_FILES\"][\"PARAMETERS\"]\n",
    "    filename = picklePath + pickleFile\n",
    "    pickle_dump(filename, allHyperparamDict)\n",
    "    \n",
    "    # seperately dump Calibration dump\n",
    "    calibDir = paramInstance.get_paramDict(\"PATH\")[\"PICKLE\"]\n",
    "    calibFile = paramInstance.get_paramDict(\"PICKLE_FILES\")[\"CALIB\"] \n",
    "    calibrationDict = paramInstance.get_paramDict(\"CAMERA_CALIBRATION\")\n",
    "    pickle_dump(calibDir + calibFile, calibrationDict)\n",
    "    \n",
    "    \n",
    "def visualize_test_images(fname, testImageInstance, paramInstance, lineInstance):\n",
    "    testDir = testImagesInstance.get_imageDict(\"PATH\")[\"TEST\"]\n",
    "    testFilename = testImagesInstance.get_imageDict(\"PICKLE_FILES\")[\"TEST\"]  \n",
    "    testImagesDict = pickle_load(testDir + testFilename)\n",
    "    \n",
    "    displayOrderSet = [ [\"ORIGINAL\",\"UNDISTORTED\",\"WARPED\",\"GRAY\" ],\n",
    "                        [\"WARPED\",\"R_CHANNEL\",\"G_CHANNEL\",\"B_CHANNEL\"], \n",
    "                        [\"WARPED\",\"H_CHANNEL\", \"L_CHANNEL\",\"S_CHANNEL\"],\n",
    "                        [\"WARPED\",\"R_BINARY\", \"G_BINARY\", \"S_BINARY\"],\n",
    "                        [\"WARPED\", \"SOBEL_ABSX\",\"SOBEL_MAG\",\"SOBEL_DIR\"],\n",
    "                        [\"WARPED\", \"GRAY_BLUR\", \"COMBINED_CHANNEL\", \"POLYWIN_IMGS\"], \n",
    "                        [\"WARPED\", \"POLYLINE_IMGS\",\"HISTOGRAM\", \"FINAL_IMG\"]\n",
    "                      ]\n",
    "    cmapSet = [\"R_BINARY\", \"G_BINARY\", \"S_BINARY\",\"SOBEL_ABSX\",\"SOBEL_MAG\",\"SOBEL_DIR\",\"GRAY\", \"GRAY_BLUR\", \"COMBINED_CHANNEL\" ]\n",
    "    \n",
    "    cols = 4\n",
    "    rows = len(displayOrderSet)\n",
    "    fig, axes= plt.subplots(nrows = rows, ncols = cols, figsize=(20,20), gridspec_kw={'hspace': 0.4, 'wspace': 0.2})\n",
    "    row = 0\n",
    "    col = 0\n",
    "    for row, keyList in enumerate(displayOrderSet) :\n",
    "        for col, key in enumerate(keyList):\n",
    "            axes[row, col].set_title(key)  #fontweight = \"bold\"  fontsize = 10 \n",
    "            if key == \"HISTOGRAM\":\n",
    "                axes[row, col].plot(testImagesDict[fname][key])\n",
    "            elif key in cmapSet:\n",
    "                axes[row, col].imshow(testImagesDict[fname][key], cmap=\"gray\")\n",
    "            elif key in [\"POLYLINE_IMGS\" ]:\n",
    "                img, left_fitx, right_fitx, ploty = testImagesDict[fname][key]\n",
    "                axes[row, col].imshow(img)\n",
    "                axes[row, col].plot(left_fitx, ploty, color='yellow')\n",
    "                axes[row, col].plot(right_fitx, ploty, color='yellow')\n",
    "            elif key in [\"POLYWIN_IMGS\"]:\n",
    "                img, left_fitx, right_fitx, ploty = testImagesDict[fname][key]\n",
    "                axes[row, col].imshow(img)\n",
    "                axes[row, col].plot(left_fitx, ploty, color='yellow')\n",
    "                axes[row, col].plot(right_fitx, ploty, color='yellow')\n",
    "            else:\n",
    "                axes[row, col].imshow(testImagesDict[fname][key])\n",
    "    \n",
    "                \n",
    "def visualize_calib_images(paramInstance, lineInstance, testImagesInstance):\n",
    "    \"\"\"\n",
    "    Displaying Calibg images with data\n",
    "    including Undisorted calib images using calibration data\n",
    "    \"\"\"\n",
    "    # Load calibration Images from pickle file\n",
    "    calibDirDict = testImagesInstance.get_imageDict(\"PATH\")\n",
    "    calibFileDict = testImagesInstance.get_imageDict(\"PICKLE_FILES\") \n",
    "    calibImagesDict = pickle_load(calibDirDict[\"CALIB\"] + calibFileDict[\"CALIB\"] )\n",
    "    \n",
    "    # Load calibration data from pickle file\n",
    "    paramDirDict = paramInstance.get_paramDict(\"PATH\")\n",
    "    paramFileDict = paramInstance.get_paramDict(\"PICKLE_FILES\") \n",
    "    calibrationData = pickle_load(paramDirDict[\"PICKLE\"] + paramFileDict[\"CALIB\"] )\n",
    "    cameraMatrix, distortionCoeff = (calibrationData[\"CAMERAMATRIX\"], calibrationData[\"DISTORTIONCOEFF\"])\n",
    "\n",
    "    withCornerSet = []\n",
    "    withUndistortedSet = []\n",
    "    displaySet = []\n",
    "    tmp = []\n",
    "    \n",
    "    for oImage in calibImagesDict[\"ORIGINAL\"]:\n",
    "        fname = oImage[0]    \n",
    "        tmp.append(\"Original-\"+ oImage[0])\n",
    "        tmp.append(oImage[1])\n",
    "        flag = False\n",
    "        for cImage in calibImagesDict[\"WITHCORNERS\"]:\n",
    "            if cImage[0] == fname:\n",
    "                tmp.append(\"With Detected Corners\")\n",
    "                tmp.append(cImage[1])\n",
    "                flag = True\n",
    "                break\n",
    "        \n",
    "        if flag:\n",
    "            withCornerSet.append(tmp)\n",
    "        else:\n",
    "            tmp.append(\"Undistorted Image\")\n",
    "            undistorted_image = undistort_image(oImage[1], cameraMatrix, distortionCoeff)\n",
    "            tmp.append(undistorted_image)\n",
    "            withUndistortedSet.append(tmp)   \n",
    "        tmp = []\n",
    "    \n",
    "    displaySet = withCornerSet[0:3] + withUndistortedSet\n",
    "    cols = 2\n",
    "    rows = 6\n",
    "    \n",
    "   \n",
    "    fig, axes= plt.subplots(nrows = rows, ncols = cols, figsize=(30,30))\n",
    "    for i, cornersData in enumerate(displaySet) :\n",
    "        axes[i, 0].set_title(cornersData[0], fontsize = 20)\n",
    "        axes[i, 0].imshow(cornersData[1])\n",
    "        axes[i, 1].set_title(cornersData[2], fontsize = 20, fontweight = \"bold\")\n",
    "        axes[i, 1].imshow(cornersData[3])\n",
    "    \n",
    "\n",
    "def measure_curvature_real(ploty, xWidth, fitData,  paramInstance, key):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    Radius of curvature is defined at maximum Y-value - i.e bottom of the image\n",
    "    '''\n",
    "    paramDict = paramInstance.get_paramDict(key)\n",
    "    ym_per_pix = paramDict[\"Y_METERS_PER_PIXEL\"] # meters per pixel in y dimension\n",
    "    xm_per_pix = paramDict[\"X_METERS_PER_PIXEL\"] # meters per pixel in x dimension\n",
    "    \n",
    "    leftFit, rightFit = fitData\n",
    "    y_max = np.max(ploty)\n",
    "    Y_meters = y_max * ym_per_pix\n",
    "    leftRoc = evaluate_polynomial_func(leftFit, Y_meters, 1) \n",
    "    rightRoc = evaluate_polynomial_func(rightFit, Y_meters, 1)\n",
    "    avgROC = (leftRoc + rightRoc)/2\n",
    "    \n",
    "    idealCarCenter = xWidth/2\n",
    "    leftX =  evaluate_polynomial_func(leftFit, Y_meters, 2) \n",
    "    rightX = evaluate_polynomial_func(rightFit, Y_meters, 2) \n",
    "    actualCarCenter= (leftX + rightX)/2\n",
    "    distanceFromLaneCenter = (idealCarCenter - actualCarCenter) * xm_per_pix\n",
    "    \n",
    "    return leftRoc, rightRoc, avgROC,  distanceFromLaneCenter\n",
    "          \n",
    "def perform_sanity_check(polyfitData, curvatureData, lineInstance):\n",
    "    \"\"\"\n",
    "    flag : \"PARALLEL\" - check if the lanes are parallel\n",
    "           \"ROC\"      - Check if Left and Right ROC are nealy same\n",
    "    \"\"\"\n",
    "    # I. Check if Lanes are parallel \n",
    "    y_bottom = 690   \n",
    "    y_middle = 360\n",
    "    y_top = 10\n",
    "    leftFit, rightFit = (polyfitData[0], polyfitData[1])\n",
    "    left_x_bottom = evaluate_polynomial_func(leftFit, y_bottom, 2) \n",
    "    left_x_middle = evaluate_polynomial_func(leftFit, y_bottom, 2) \n",
    "    left_x_top    = evaluate_polynomial_func(leftFit, y_bottom, 2) \n",
    "    \n",
    "    right_x_bottom = evaluate_polynomial_func(rightFit, y_bottom, 2) \n",
    "    right_x_middle = evaluate_polynomial_func(rightFit, y_bottom, 2) \n",
    "    right_x_top    = evaluate_polynomial_func(rightFit, y_bottom, 2) \n",
    "    \n",
    "    bottom_dist = right_x_bottom  -  left_x_bottom\n",
    "    mid_dist = right_x_middle -  left_x_middle\n",
    "    top_dist = right_x_top -  left_x_top\n",
    "\n",
    "    parallelCheck = True\n",
    "    if (np.abs(bottom_dist - mid_dist) > 50 and np.abs(mid_dist - top_dist) > 50):\n",
    "        parallelCheck = False\n",
    "    \n",
    "    # I. Check if ROC for Left and right are close to Same value\n",
    "    # Note: For Straight Lines the difference will be anywhere between 3000 to 7000\n",
    "    leftRoc, rightRoc = (curvatureData[0], curvatureData[1])\n",
    "    ROCCheck = True\n",
    "    ROCDiff = np.abs(leftRoc - rightRoc)\n",
    "    \n",
    "    if ROCDiff > 10000:  # For StraightLines the ROC is very high -- Checking for Worst\n",
    "        ROCCheck = False\n",
    "        \n",
    "    sanityCheckDict = {\"BOTTOM_DIST\" : bottom_dist,\n",
    "                       \"MID_DIST\" : mid_dist,\n",
    "                       \"TOP_DIST\" : top_dist,\n",
    "                       \"BMID_DIFF\": np.abs(bottom_dist - mid_dist),\n",
    "                       \"MIDT_DIFF\": np.abs(mid_dist - top_dist),\n",
    "                       \"ROCdiff\"  : ROCDiff\n",
    "                      }\n",
    "    \n",
    "    laneDetected = True\n",
    "    if not (parallelCheck and ROCCheck):\n",
    "        laneDetected = False\n",
    "    return laneDetected, sanityCheckDict\n",
    "          \n",
    "def unpickle_calibration_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        calibrationData = pickle.load(f)\n",
    "        return (calibrationData[\"CAMERAMATRIX\"], calibrationData[\"DISTORTIONCOEFF\"])\n",
    "\n",
    "\n",
    "def update_lineInstance(polyfitData, pixelPositions, curvatureData, laneDetected, sanityCheckDict, lineInstance):\n",
    "    lineInstance.detected = laneDetected  \n",
    "    lineInstance.frameCount += 1\n",
    "    if not laneDetected:\n",
    "        lineInstance.badFrames += 1\n",
    "        \n",
    "    if lineInstance.badFrames > 5:\n",
    "        lineInstance.badFrames = 0\n",
    "    \n",
    "    lineInstance.polyFitDataCurrent = polyfitData\n",
    "    lineInstance.ROCData.append(curvatureData)\n",
    "                                            \n",
    "    N = len(lineInstance.polyFitDataQueue)\n",
    "    \n",
    "    if (N >= 10):\n",
    "        fitdata = (polyfitData[0], polyfitData[1])\n",
    "        polyFitDiff = np.subtract(lineInstance.polyFitDataQueue[N-1], polyfitData)\n",
    "        polyfitDataPopped = lineInstance.polyFitDataQueue.popleft()\n",
    "        pixelPositionsPopped = lineInstance.pixelPositionsQueue.popleft()\n",
    "        \n",
    "        lineInstance.polyFitDataQueue.append(polyfitData)\n",
    "        lineInstance.pixelPositionsQueue.append(pixelPositions)\n",
    "        \n",
    "        sum0, sum1 = lineInstance.polyfitDataSum\n",
    "        sum0 = np.subtract(lineInstance.polyfitDataSum[0], polyfitData[0])\n",
    "        sum1 = np.subtract(lineInstance.polyfitDataSum[1], polyfitData[1])\n",
    "        \n",
    "        sum0 += polyfitData[0]\n",
    "        sum1 += polyfitData[1]\n",
    "        \n",
    "        lineInstance.polyfitDataSum = (sum0, sum1)\n",
    "        \n",
    "        avg1 = lineInstance.polyfitDataSum[0]/len(lineInstance.polyFitDataQueue)\n",
    "        avg2 = lineInstance.polyfitDataSum[1]/len(lineInstance.polyFitDataQueue)\n",
    "        lineInstance.polyfitDataAvg = (avg1, avg2) \n",
    "        \n",
    "    if (N == 0):\n",
    "        lineInstance.polyFitDataQueue.append(polyfitData)\n",
    "        lineInstance.pixelPositionsQueue.append(pixelPositions)\n",
    "        lineInstance.polyfitDataSum = (polyfitData[0],polyfitData[1])\n",
    "        lineInstance.polyfitDataAvg = (polyfitData[0],polyfitData[1])\n",
    "    \n",
    "    elif (N > 0 and N < 5):\n",
    "        polyFitDiff = np.subtract(lineInstance.polyFitDataQueue[N-1], polyfitData)\n",
    "        lineInstance.polyFitDataQueue.append(polyfitData)\n",
    "        lineInstance.pixelPositionsQueue.append(pixelPositions)\n",
    "        N = len(lineInstance.polyFitDataQueue)\n",
    "        left_fit, right_fit, left_fitx, right_fitx = lineInstance.polyFitDataQueue[0]\n",
    "        leftFitStack = left_fit\n",
    "        rightFitStack = right_fit\n",
    "        for i in range(1,N):\n",
    "            left_fit, right_fit, left_fitx, right_fitx = lineInstance.polyFitDataQueue[i]\n",
    "            leftFitStack = np.vstack((left_fit, leftFitStack))\n",
    "            rightFitStack = np.vstack((right_fit, rightFitStack))\n",
    "        \n",
    "        polyfitDataSumTemp = (np.sum(leftFitStack, axis = 0),\n",
    "                              np.sum(rightFitStack, axis = 0),\n",
    "                              )\n",
    "        lineInstance.polyfitDataSum = polyfitDataSumTemp\n",
    "        avg1 = lineInstance.polyfitDataSum[0]/len(lineInstance.polyFitDataQueue)\n",
    "        avg2 = lineInstance.polyfitDataSum[1]/len(lineInstance.polyFitDataQueue)\n",
    "        lineInstance.polyfitDataAvg = (avg1, avg2) \n",
    "\n",
    "        \n",
    "def test_pipeline(paramInstance, lineInstance, testImagesInstance):\n",
    "    mode = \"TESTRUN\"\n",
    "    pathDict = paramInstance.get_paramDict(\"PATH\")\n",
    "    testPath = pathDict[\"TEST\"]\n",
    "    calibDict = paramInstance.get_paramDict(\"CAMERA_CALIBRATION\")\n",
    "    cameraMatrix, distortionCoeff = (calibDict[\"CAMERAMATRIX\"], calibDict[\"DISTORTIONCOEFF\"])\n",
    "    run_index = 0\n",
    "    for index, filename in enumerate(glob.glob(testPath + \"*.jpg\")):\n",
    "        fname = filename.replace(testPath,\"\")\n",
    "        testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname] = {}\n",
    "        distortedImage = mpimg.imread(filename)\n",
    "        undistortedImage = undistort_image(distortedImage, cameraMatrix, distortionCoeff)\n",
    "        if index == 0:\n",
    "            imgHeight, imgWidth = (undistortedImage.shape[0], undistortedImage.shape[1])\n",
    "            imgSize_YX =  (imgHeight, imgWidth)\n",
    "            imgSize_XY =  (imgWidth,imgHeight)\n",
    "            ploty = np.linspace(0, imgHeight-1, imgHeight)\n",
    "            M, MInv = tranformation_matrices(imgSize_YX, paramInstance, \"TRANFORMATION_MATRICES\")\n",
    "\n",
    "        warpedImage = topview_perspective_transform(undistortedImage, M, imgSize_XY, paramInstance, \"TOPVIEW_PERSPECTIVE_TRANSFORM\")\n",
    "        combinedImage = gradient_by_color_and_filter(fname, warpedImage, paramInstance, \"GRADIENT_BY_COLOR_AND_FILTER\", testImagesInstance, mode)\n",
    "        polyfitData, pixelPositions = initial_fit_polynomial(fname, combinedImage, ploty, paramInstance, \"INITIAL_FIT_POLYNOMIAL\", testImagesInstance, mode) \n",
    "        \n",
    "        fitData = (polyfitData[0], polyfitData[1])     # left_fit, right_fit => coefficients\n",
    "        fitXData = (polyfitData[2], polyfitData[3])    # left_fitx , right_fitx => pixelCoordinates\n",
    "        curvatureData = measure_curvature_real(ploty, imgWidth, fitData, paramInstance, \"MEASURE_CURVATURE_REAL\" )   \n",
    "        laneDetected, sanityCheckDict = perform_sanity_check(polyfitData, curvatureData, lineInstance)\n",
    "        print(f\"Sanity check for image {filename} - Lane Detection : {laneDetected}\")\n",
    "        finalImg = draw_final_lanes(undistortedImage, combinedImage, imgSize_XY, MInv, ploty, fitXData, curvatureData, paramInstance, \"DRAW_FINAL_LANES\" )\n",
    "        update_lineInstance(polyfitData, pixelPositions, curvatureData, laneDetected, sanityCheckDict , lineInstance)\n",
    "\n",
    "        if mode == \"TESTRUN\":\n",
    "            testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"ORIGINAL\"] = distortedImage\n",
    "            testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"UNDISTORTED\"] = undistortedImage\n",
    "            testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"WARPED\"] = warpedImage\n",
    "            testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"COMBINED_CHANNEL\"] = combinedImage\n",
    "            testImagesInstance.SAVED_IMAGES_DICT[\"TEST_IMAGES\"][fname][\"FINAL_IMG\"] = finalImg\n",
    "            pickledump_all_images(testImagesInstance)\n",
    "            pickledump_all_Hyperparameters(paramInstance)\n",
    "        \n",
    "def prod_pipeline(paramInstance, lineInstance, testImagesInstance, cameraMatrix, distortionCoeff):\n",
    "    mode = \"PRODRUN\"\n",
    "    fname = \"PRODRUN\"  # Just dummy name to have the functions working\n",
    "    distortedImage = mpimg.imread(filename)\n",
    "    undistortedImage = undistort_image(distortedImage, cameraMatrix, distortionCoeff)\n",
    "    if lineInstance.frameCount == 0:\n",
    "        imgHeight, imgWidth = (undistortedImage.shape[0], undistortedImage.shape[1])\n",
    "        imgSize_YX =  (imgHeight, imgWidth)\n",
    "        imgSize_XY =  (imgWidth,imgHeight)\n",
    "        ploty = np.linspace(0, imgHeight-1, imgHeight)\n",
    "        M, MInv = tranformation_matrices(imgSize_YX, paramInstance, \"TRANFORMATION_MATRICES\")\n",
    "    \n",
    "    warpedImage = topview_perspective_transform(undistortedImage, M, imgSize_XY, paramInstance, \"TOPVIEW_PERSPECTIVE_TRANSFORM\")\n",
    "    combinedImage = gradient_by_color_and_filter(fname, warpedImage, paramInstance, \"GRADIENT_BY_COLOR_AND_FILTER\", testImagesInstance, mode)\n",
    "    \n",
    "    if lineInstance.frameCount == 0 or lineInstance.badFrames > 5:\n",
    "        lineInstance.badFrames = 0\n",
    "        polyfitData, pixelPositions = initial_fit_polynomial(fname, combinedImage, ploty, paramInstance, \"INITIAL_FIT_POLYNOMIAL\", testImagesInstance, mode) \n",
    "    else:\n",
    "        fitData = (lineInstance.polyfitDataAvg[0], lineInstance.polyfitDataAvg[1]) \n",
    "        polyfitData, pixelPositions = fitpoly_using_priorfit(binaryImage, ploty, fitData, paramInstance, \"FITPOLY_USING_PRIORFIT\",testImagesInstance, mode )\n",
    "    \n",
    "    fitData = (polyfitData[0], polyfitData[1])     # left_fit, right_fit => coefficients\n",
    "    fitXData = (polyfitData[2], polyfitData[3])    # left_fitx , right_fitx => pixelCoordinates\n",
    "       \n",
    "    curvatureData = measure_curvature_real(ploty, imgWidth, fitData, paramInstance, \"MEASURE_CURVATURE_REAL\" )   \n",
    "    laneDetected, sanityCheckDict = perform_sanity_check(polyfitData, curvatureData, lineInstance)\n",
    "    if laneDetected:\n",
    "        finalImg = draw_final_lanes(undistortedImage, combinedImage, imgSize_XY, MInv, ploty, fitXData, curvatureData, paramInstance, \"DRAW_FINAL_LANES\" )\n",
    "    update_lineInstance(polyfitData, pixelPositions, curvatureData, laneDetected, sanityCheckDict , lineInstance)\n",
    "\n",
    "def initialize_env():\n",
    "    paramInstance = HyperParameters()\n",
    "    lineInstance = Line()\n",
    "    testImagesInstance = Save_Images()\n",
    "\n",
    "    dirDict = paramInstance.get_paramDict(\"PATH\")\n",
    "    fileDict = paramInstance.get_paramDict(\"PICKLE_FILES\")\n",
    "    calibPickleFile = dirDict[\"PICKLE\"] + fileDict[\"CALIB\"] \n",
    "    calibImagesPath = dirDict[\"CALIB\"]\n",
    "    if (not os.path.exists(calibPickleFile)):\n",
    "        camera_calibration(calibImagesPath, paramInstance, \"CAMERA_CALIBRATION\", testImagesInstance)\n",
    "    else:\n",
    "        cameraMatrix, distortionCoeff = unpickle_calibration_data(calibPickleFile)\n",
    "        updateDict = {\"CAMERA_CALIBRATION\" : {\"CAMERAMATRIX\" : cameraMatrix,\n",
    "                                              \"DISTORTIONCOEFF\" : distortionCoeff\n",
    "                                            }\n",
    "                     }\n",
    "        paramInstance.set_paramDict(updateDict)\n",
    "    return paramInstance, lineInstance, testImagesInstance, cameraMatrix, distortionCoeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramInstance, lineInstance, testImagesInstance, cameraMatrix, distortionCoeff = initialize_env()\n",
    "test_pipeline(paramInstance, lineInstance, testImagesInstance)\n",
    "#visualize_test_images(\"test1.jpg\",testImagesInstance, paramInstance, lineInstance)\n",
    "visualize_test_images(\"straight_lines1.jpg\",testImagesInstance, paramInstance, lineInstance)\n",
    "#visualize_calib_images(paramInstance, lineInstance, testImagesInstance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_pipeline_with_smoothing():\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    #original_img = mpimg.imread(path+filename)\n",
    "    # 1. Convert image to gray scale and detect the edges\n",
    "    mode = \"PRODRUN\"\n",
    "    fname = \"PRODRUN\"\n",
    "    distortedImage = image\n",
    "    undistortedImage = undistort_image(distortedImage, cameraMatrix, distortionCoeff)\n",
    "    #if lineInstance.frameCount == 0:\n",
    "    imgHeight, imgWidth = (undistortedImage.shape[0], undistortedImage.shape[1])\n",
    "    imgSize_YX =  (imgHeight, imgWidth)\n",
    "    imgSize_XY =  (imgWidth,imgHeight)\n",
    "    ploty = np.linspace(0, imgHeight-1, imgHeight)\n",
    "    M, MInv = tranformation_matrices(imgSize_YX, paramInstance, \"TRANFORMATION_MATRICES\")\n",
    "    \n",
    "    warpedImage = topview_perspective_transform(undistortedImage, M, imgSize_XY, paramInstance, \"TOPVIEW_PERSPECTIVE_TRANSFORM\")\n",
    "    combinedImage = gradient_by_color_and_filter(fname, warpedImage, paramInstance, \"GRADIENT_BY_COLOR_AND_FILTER\", testImagesInstance, mode)\n",
    "    #or lineInstance.badFrames > 5:\n",
    "    #if lineInstance.frameCount == 0:\n",
    "        #lineInstance.badFrames = 0\n",
    "    polyfitData, pixelPositions = initial_fit_polynomial(fname, combinedImage, ploty, paramInstance, \"INITIAL_FIT_POLYNOMIAL\", testImagesInstance, mode) \n",
    "    #else:\n",
    "    #    fitData = (lineInstance.polyfitDataAvg[0], lineInstance.polyfitDataAvg[1]) \n",
    "    #    polyfitData, pixelPositions = fitpoly_using_priorfit(combinedImage, ploty, fitData, paramInstance, \"FITPOLY_USING_PRIORFIT\",testImagesInstance, mode )\n",
    "    \n",
    "    fitData = (polyfitData[0], polyfitData[1])     # left_fit, right_fit => coefficients\n",
    "    fitXData = (polyfitData[2], polyfitData[3])    # left_fitx , right_fitx => pixelCoordinates\n",
    "       \n",
    "    curvatureData = measure_curvature_real(ploty, imgWidth, fitData, paramInstance, \"MEASURE_CURVATURE_REAL\" )   \n",
    "    #laneDetected, sanityCheckDict = perform_sanity_check(polyfitData, curvatureData, lineInstance)\n",
    "    #if laneDetected:\n",
    "    finalImg = draw_final_lanes(undistortedImage, combinedImage, imgSize_XY, MInv, ploty, fitXData, curvatureData, paramInstance, \"DRAW_FINAL_LANES\" )\n",
    "    #update_lineInstance(polyfitData, pixelPositions, curvatureData, laneDetected, sanityCheckDict , lineInstance)\n",
    "\n",
    "    return finalImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramInstance, lineInstance, testImagesInstance, cameraMatrix, distortionCoeff = initialize_env()\n",
    "lineInstance.frameCount = 0\n",
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    #original_img = mpimg.imread(path+filename)\n",
    "    # 1. Convert image to gray scale and detect the edges\n",
    "    mode = \"PRODRUN\"\n",
    "    fname = \"PRODRUN\"\n",
    "    distortedImage = image\n",
    "    undistortedImage = undistort_image(distortedImage, cameraMatrix, distortionCoeff)\n",
    "    #if lineInstance.frameCount == 0:\n",
    "    imgHeight, imgWidth = (undistortedImage.shape[0], undistortedImage.shape[1])\n",
    "    imgSize_YX =  (imgHeight, imgWidth)\n",
    "    imgSize_XY =  (imgWidth,imgHeight)\n",
    "    ploty = np.linspace(0, imgHeight-1, imgHeight)\n",
    "    M, MInv = tranformation_matrices(imgSize_YX, paramInstance, \"TRANFORMATION_MATRICES\")\n",
    "    \n",
    "    warpedImage = topview_perspective_transform(undistortedImage, M, imgSize_XY, paramInstance, \"TOPVIEW_PERSPECTIVE_TRANSFORM\")\n",
    "    combinedImage = gradient_by_color_and_filter(fname, warpedImage, paramInstance, \"GRADIENT_BY_COLOR_AND_FILTER\", testImagesInstance, mode)\n",
    "    #or lineInstance.badFrames > 5:\n",
    "    #if lineInstance.frameCount == 0:\n",
    "        #lineInstance.badFrames = 0\n",
    "    polyfitData, pixelPositions = initial_fit_polynomial(fname, combinedImage, ploty, paramInstance, \"INITIAL_FIT_POLYNOMIAL\", testImagesInstance, mode) \n",
    "    #else:\n",
    "    #    fitData = (lineInstance.polyfitDataAvg[0], lineInstance.polyfitDataAvg[1]) \n",
    "    #    polyfitData, pixelPositions = fitpoly_using_priorfit(combinedImage, ploty, fitData, paramInstance, \"FITPOLY_USING_PRIORFIT\",testImagesInstance, mode )\n",
    "    \n",
    "    fitData = (polyfitData[0], polyfitData[1])     # left_fit, right_fit => coefficients\n",
    "    fitXData = (polyfitData[2], polyfitData[3])    # left_fitx , right_fitx => pixelCoordinates\n",
    "       \n",
    "    curvatureData = measure_curvature_real(ploty, imgWidth, fitData, paramInstance, \"MEASURE_CURVATURE_REAL\" )   \n",
    "    #laneDetected, sanityCheckDict = perform_sanity_check(polyfitData, curvatureData, lineInstance)\n",
    "    #if laneDetected:\n",
    "    finalImg = draw_final_lanes(undistortedImage, combinedImage, imgSize_XY, MInv, ploty, fitXData, curvatureData, paramInstance, \"DRAW_FINAL_LANES\" )\n",
    "    #update_lineInstance(polyfitData, pixelPositions, curvatureData, laneDetected, sanityCheckDict , lineInstance)\n",
    "\n",
    "    return finalImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "white_output = '../test_videos_output/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclip = VideoFileClip(\"../test_videos_output/project_video.mp4\")\n",
    "myclip.write_gif(\"test.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
